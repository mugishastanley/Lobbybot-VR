# What is this
This repo contains the human intention detection and the motion prediction strategies VR part of the lobby bot project.  ##lobbybot project. [link](https://www.lobbybot.fr/). </br>
The Strategies use sensor data from the trackers and the eye tracking functionality of the vive pro eye and the data is fused to predict a point of human interaction. </br>
One tracker is attached to the human dominant hand while another one sensor is used as a tracking reference.

# How do I use the code?.
<ol>
<li>Set up the HTC Vive tracking System </li>
<li>Install Unity VR Software . we recommend version 19.06 </li>
<li>Install steam VR in unity</li>
<li>Setup the HTC Vive eye pro to work with unity </li>
<li>Install the Toobi sdk for eye tracking </li>
<li>Hit the Play button <li>
</ol>
If you find this repo helpful, please cite the following paper/s
<ol>

<li>S. Mugisha, M. Zoppi, R. Molfino, V. K. Guda, C. Chevallereau, D. Chablat. <i>“Safe collaboration between human and robot in a context of intermittent haptique interface“. </i>
ASME International Design Engineering Technical Conferences & Computers and Information in Engineering Conference, Virtual, United States, Aug 2021. </li>

<li>Guda, V., Mugisha, S., Chevallereau, C., Zoppi, M., Molfino, R., and Chablat, D. (May 6, 2022). "Motion Strategies for a Cobot in a Context of Intermittent Haptic Interface." ASME. J. Mechanisms Robotics. doi: https://doi.org/10.1115/1.4054509 </li>
</ol>

# Related Videos are available on youtube. [Video](https://www.youtube.com/watch?v=wz0dJjk4-qk)
